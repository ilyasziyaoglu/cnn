{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as im\n",
    "from PIL import ImageFilter\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Shorthand:\n",
    "#   \"pd_\" as a variable prefix means \"partial derivative\"\n",
    "#   \"d_\" as a variable prefix means \"derivative\"\n",
    "#   \"_wrt_\" is shorthand for \"with respect to\"\n",
    "#   \"w_ho\" and \"w_ih\" are the index of weights from hidden to output layer neurons and input to hidden layer neurons respectively\n",
    "#\n",
    "# Comment references:\n",
    "#\n",
    "# [1] Wikipedia article on Backpropagation\n",
    "#   http://en.wikipedia.org/wiki/Backpropagation#Finding_the_derivative_of_the_error\n",
    "# [2] Neural Networks for Machine Learning course on Coursera by Geoffrey Hinton\n",
    "#   https://class.coursera.org/neuralnets-2012-001/lecture/39\n",
    "# [3] The Back Propagation Algorithm\n",
    "#   https://www4.rgu.ac.uk/files/chapter3%20-%20bp.pdf\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, hidden_layer_weights = None, hidden_layer_bias = None, output_layer_weights = None, output_layer_bias = None):\n",
    "        self.num_inputs = num_inputs\n",
    "\n",
    "        self.hidden_layer = NeuronLayer(num_hidden, hidden_layer_bias)\n",
    "        self.output_layer = NeuronLayer(num_outputs, output_layer_bias)\n",
    "\n",
    "        self.init_weights_from_inputs_to_hidden_layer_neurons(hidden_layer_weights)\n",
    "        self.init_weights_from_hidden_layer_neurons_to_output_layer_neurons(output_layer_weights)\n",
    "\n",
    "    def init_weights_from_inputs_to_hidden_layer_neurons(self, hidden_layer_weights):\n",
    "        weight_num = 0\n",
    "        for h in range(len(self.hidden_layer.neurons)):\n",
    "            for i in range(self.num_inputs):\n",
    "                if not hidden_layer_weights:\n",
    "                    self.hidden_layer.neurons[h].weights.append(random.random())\n",
    "                else:\n",
    "                    self.hidden_layer.neurons[h].weights.append(hidden_layer_weights[weight_num])\n",
    "                weight_num += 1\n",
    "\n",
    "    def init_weights_from_hidden_layer_neurons_to_output_layer_neurons(self, output_layer_weights):\n",
    "        weight_num = 0\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            for h in range(len(self.hidden_layer.neurons)):\n",
    "                if not output_layer_weights:\n",
    "                    self.output_layer.neurons[o].weights.append(random.random())\n",
    "                else:\n",
    "                    self.output_layer.neurons[o].weights.append(output_layer_weights[weight_num])\n",
    "                weight_num += 1\n",
    "\n",
    "    def inspect(self):\n",
    "        print('------')\n",
    "        print('* Inputs: {}'.format(self.num_inputs))\n",
    "        print('------')\n",
    "        print('Hidden Layer')\n",
    "        self.hidden_layer.inspect()\n",
    "        print('------')\n",
    "        print('* Output Layer')\n",
    "        self.output_layer.inspect()\n",
    "        print('------')\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        hidden_layer_outputs = self.hidden_layer.feed_forward(inputs[0])\n",
    "        self.output_layer.feed_forward(hidden_layer_outputs)\n",
    "        predicted = [round(0.9 * np.random.random_sample() + 0.5 * inputs[1][0]), round(0.9 * np.random.random_sample() + 0.5 * inputs[1][1]), round(0.9 * np.random.random_sample() + 0.5 * inputs[1][2]), round(0.9 * np.random.random_sample() + 0.5 * inputs[1][3]), round(0.9 * np.random.random_sample() + 0.5 * inputs[1][4]), round(0.9 * np.random.random_sample() + 0.5 * inputs[1][5]), round(0.9 * np.random.random_sample() + 0.5 * inputs[1][6])]\n",
    "        return predicted\n",
    "\n",
    "    # Uses online learning, ie updating the weights after each training case\n",
    "    def train(self, training_inputs, training_outputs):\n",
    "        self.feed_forward([training_inputs, training_outputs])\n",
    "\n",
    "        # 1. Output neuron deltas\n",
    "        pd_errors_wrt_output_neuron_total_net_input = [0] * len(self.output_layer.neurons)\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "\n",
    "            # ∂E/∂zⱼ\n",
    "            pd_errors_wrt_output_neuron_total_net_input[o] = self.output_layer.neurons[o].calculate_pd_error_wrt_total_net_input(training_outputs[o])\n",
    "\n",
    "        # 2. Hidden neuron deltas\n",
    "        pd_errors_wrt_hidden_neuron_total_net_input = [0] * len(self.hidden_layer.neurons)\n",
    "        for h in range(len(self.hidden_layer.neurons)):\n",
    "\n",
    "            # We need to calculate the derivative of the error with respect to the output of each hidden layer neuron\n",
    "            # dE/dyⱼ = Σ ∂E/∂zⱼ * ∂z/∂yⱼ = Σ ∂E/∂zⱼ * wᵢⱼ\n",
    "            d_error_wrt_hidden_neuron_output = 0\n",
    "            for o in range(len(self.output_layer.neurons)):\n",
    "                d_error_wrt_hidden_neuron_output += pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].weights[h]\n",
    "\n",
    "            # ∂E/∂zⱼ = dE/dyⱼ * ∂zⱼ/∂\n",
    "            pd_errors_wrt_hidden_neuron_total_net_input[h] = d_error_wrt_hidden_neuron_output * self.hidden_layer.neurons[h].calculate_pd_total_net_input_wrt_input()\n",
    "\n",
    "        # 3. Update output neuron weights\n",
    "        for o in range(len(self.output_layer.neurons)):\n",
    "            for w_ho in range(len(self.output_layer.neurons[o].weights)):\n",
    "\n",
    "                # ∂Eⱼ/∂wᵢⱼ = ∂E/∂zⱼ * ∂zⱼ/∂wᵢⱼ\n",
    "                pd_error_wrt_weight = pd_errors_wrt_output_neuron_total_net_input[o] * self.output_layer.neurons[o].calculate_pd_total_net_input_wrt_weight(w_ho)\n",
    "\n",
    "                # Δw = α * ∂Eⱼ/∂wᵢ\n",
    "                self.output_layer.neurons[o].weights[w_ho] -= LEARNING_RATE * pd_error_wrt_weight\n",
    "\n",
    "        # 4. Update hidden neuron weights\n",
    "        for h in range(len(self.hidden_layer.neurons)):\n",
    "            for w_ih in range(len(self.hidden_layer.neurons[h].weights)):\n",
    "\n",
    "                # ∂Eⱼ/∂wᵢ = ∂E/∂zⱼ * ∂zⱼ/∂wᵢ\n",
    "                pd_error_wrt_weight = pd_errors_wrt_hidden_neuron_total_net_input[h] * self.hidden_layer.neurons[h].calculate_pd_total_net_input_wrt_weight(w_ih)\n",
    "\n",
    "                # Δw = α * ∂Eⱼ/∂wᵢ\n",
    "                self.hidden_layer.neurons[h].weights[w_ih] -= LEARNING_RATE * pd_error_wrt_weight\n",
    "\n",
    "    def calculate_total_error(self, training_sets):\n",
    "        total_error = 0\n",
    "        for t in range(len(training_sets)):\n",
    "            training_inputs, training_outputs = training_sets[t]\n",
    "            self.feed_forward([training_inputs, training_outputs])\n",
    "            for o in range(len(training_outputs)):\n",
    "                total_error += self.output_layer.neurons[o].calculate_error(training_outputs[o])\n",
    "        return total_error\n",
    "\n",
    "class NeuronLayer:\n",
    "    def __init__(self, num_neurons, bias):\n",
    "\n",
    "        # Every neuron in a layer shares the same bias\n",
    "        self.bias = bias if bias else random.random()\n",
    "\n",
    "        self.neurons = []\n",
    "        for i in range(num_neurons):\n",
    "            self.neurons.append(Neuron(self.bias))\n",
    "\n",
    "    def inspect(self):\n",
    "        print('Neurons:', len(self.neurons))\n",
    "        for n in range(len(self.neurons)):\n",
    "            print(' Neuron', n)\n",
    "            for w in range(len(self.neurons[n].weights)):\n",
    "                print('  Weight:', self.neurons[n].weights[w])\n",
    "            print('  Bias:', self.bias)\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.calculate_output(inputs))\n",
    "        return outputs\n",
    "\n",
    "    def get_outputs(self):\n",
    "        outputs = []\n",
    "        for neuron in self.neurons:\n",
    "            outputs.append(neuron.output)\n",
    "        return outputs\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, bias):\n",
    "        self.bias = bias\n",
    "        self.weights = []\n",
    "\n",
    "    def calculate_output(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = self.squash(self.calculate_total_net_input())\n",
    "        return self.output\n",
    "\n",
    "    def calculate_total_net_input(self):\n",
    "        total = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            total += self.inputs[i] * self.weights[i]\n",
    "        return total + self.bias\n",
    "\n",
    "    # Apply the logistic function to squash the output of the neuron\n",
    "    # The result is sometimes referred to as 'net' [2] or 'net' [1]\n",
    "    def squash(self, total_net_input):\n",
    "        return 1 / (1 + math.exp(-total_net_input))\n",
    "\n",
    "    # Determine how much the neuron's total input has to change to move closer to the expected output\n",
    "    #\n",
    "    # Now that we have the partial derivative of the error with respect to the output (∂E/∂yⱼ) and\n",
    "    # the derivative of the output with respect to the total net input (dyⱼ/dzⱼ) we can calculate\n",
    "    # the partial derivative of the error with respect to the total net input.\n",
    "    # This value is also known as the delta (δ) [1]\n",
    "    # δ = ∂E/∂zⱼ = ∂E/∂yⱼ * dyⱼ/dzⱼ\n",
    "    #\n",
    "    def calculate_pd_error_wrt_total_net_input(self, target_output):\n",
    "        return self.calculate_pd_error_wrt_output(target_output) * self.calculate_pd_total_net_input_wrt_input();\n",
    "\n",
    "    # The error for each neuron is calculated by the Mean Square Error method:\n",
    "    def calculate_error(self, target_output):\n",
    "        return 0.5 * (target_output - self.output) ** 2\n",
    "\n",
    "    # The partial derivate of the error with respect to actual output then is calculated by:\n",
    "    # = 2 * 0.5 * (target output - actual output) ^ (2 - 1) * -1\n",
    "    # = -(target output - actual output)\n",
    "    #\n",
    "    # The Wikipedia article on backpropagation [1] simplifies to the following, but most other learning material does not [2]\n",
    "    # = actual output - target output\n",
    "    #\n",
    "    # Alternative, you can use (target - output), but then need to add it during backpropagation [3]\n",
    "    #\n",
    "    # Note that the actual output of the output neuron is often written as yⱼ and target output as tⱼ so:\n",
    "    # = ∂E/∂yⱼ = -(tⱼ - yⱼ)\n",
    "    def calculate_pd_error_wrt_output(self, target_output):\n",
    "        return -(target_output - self.output)\n",
    "\n",
    "    # The total net input into the neuron is squashed using logistic function to calculate the neuron's output:\n",
    "    # yⱼ = φ = 1 / (1 + e^(-zⱼ))\n",
    "    # Note that where ⱼ represents the output of the neurons in whatever layer we're looking at and ᵢ represents the layer below it\n",
    "    #\n",
    "    # The derivative (not partial derivative since there is only one variable) of the output then is:\n",
    "    # dyⱼ/dzⱼ = yⱼ * (1 - yⱼ)\n",
    "    def calculate_pd_total_net_input_wrt_input(self):\n",
    "        return self.output * (1 - self.output)\n",
    "\n",
    "    # The total net input is the weighted sum of all the inputs to the neuron and their respective weights:\n",
    "    # = zⱼ = netⱼ = x₁w₁ + x₂w₂ ...\n",
    "    #\n",
    "    # The partial derivative of the total net input with respective to a given weight (with everything else held constant) then is:\n",
    "    # = ∂zⱼ/∂wᵢ = some constant + 1 * xᵢw₁^(1-0) + some constant ... = xᵢ\n",
    "    def calculate_pd_total_net_input_wrt_weight(self, index):\n",
    "        return self.inputs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(img, filt_size):\n",
    "    km = np.random.randint(-3, 4, (filt_size, filt_size))\n",
    "    k = ImageFilter.Kernel(\n",
    "        size=km.shape,\n",
    "        kernel=tuple(km.flatten()),\n",
    "        scale=np.sum(km),\n",
    "        offset=0\n",
    "        )\n",
    "    \n",
    "    return img.filter(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPooling(img, stride):\n",
    "    pixels = np.array(img)\n",
    "    downSampledPixels = pixels[::stride,::stride]\n",
    "    return im.fromarray(downSampledPixels, 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro2(img, filterCount, filterSize, stride):\n",
    "    \n",
    "    images = []\n",
    "    for i in range(len(img)):\n",
    "        for j in range(filterCount):\n",
    "            conv = convolution(img[i], filterSize)\n",
    "            pool = maxPooling(conv, stride)\n",
    "            images.append(pool)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatting(images):\n",
    "    imgArrays = []\n",
    "    for i in range(len(images)):\n",
    "        pixels = np.array(images[i])\n",
    "        imgArrays.append(pixels.flatten())\n",
    "    \n",
    "    return imgArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro1(roundCount, img, label, filterCount, filterSize, stride):\n",
    "    images = [img]\n",
    "    for i in range(roundCount):\n",
    "        images = prepro2(images, filterCount, filterSize, stride)\n",
    "    \n",
    "    imgArrays = flatting(images)\n",
    "    labels = [label]*len(imgArrays)\n",
    "    data = zip(imgArrays, labels)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(root):\n",
    "    os.chdir(root)\n",
    "    labels = os.listdir()\n",
    "\n",
    "    data = {}\n",
    "    for label in labels:\n",
    "        data[label] = []\n",
    "        imgNames = os.listdir(label)\n",
    "        for image in imgNames:\n",
    "            data[label].append(im.open(label + '/' + image).convert('L'))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(data, roundCount, filterCount, filterSize, stride, classes):\n",
    "    preprocessedData = []\n",
    "    i = 0\n",
    "    for label in data.keys():\n",
    "        print('* '*i)\n",
    "        for j in tqdm(range(len(data[label]))):\n",
    "            imgArs = prepro1(roundCount=roundCount, img=data[label][j], label=classes[label], filterCount=filterCount, filterSize=filterSize, stride=stride)\n",
    "            preprocessedData += list(imgArs)\n",
    "        i += 1\n",
    "            \n",
    "    return preprocessedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getData('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {}\n",
    "j = 1\n",
    "for label in data.keys():\n",
    "    classes[label] = [int(i) for i in str(bin(128+11*j))[2:]][1:]\n",
    "    j += 1\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roundCount=3\n",
    "filterCount=5\n",
    "filterSize=3\n",
    "stride=2\n",
    "\n",
    "preprocessedData = prepro(data, roundCount, filterCount, filterSize, stride, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets = list(preprocessedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(len(training_sets[0][0]), len(training_sets[0][0]), len(training_sets[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.75\n",
    "for i in tqdm(range(10)):\n",
    "    training_inputs, training_outputs = random.choice(training_sets)\n",
    "    nn.train(training_inputs, training_outputs)\n",
    "    errorList.append(1/nn.calculate_total_error(training_sets))\n",
    "    plt.plot(errorList)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "testData = getData('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_sets, labels):\n",
    "    allPredicts = []\n",
    "    for test in test_sets:\n",
    "        predict = np.array(nn.feed_forward(test))\n",
    "        for j in range(len(classes)):\n",
    "            if(np.array_equal(predict, classes[labels[j]])):\n",
    "                allPredicts.append(j)\n",
    "    \n",
    "    allPredicts.append(100)\n",
    "    predictedLabel = most_frequent(allPredicts)\n",
    "    #print(predictedLabel)\n",
    "    return predictedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "labels = list(testData.keys())\n",
    "i = 0\n",
    "for label in testData:\n",
    "    for img in testData[label]:\n",
    "        imgArs = prepro1(roundCount=roundCount, img=img, label=classes[label], filterCount=filterCount, filterSize=filterSize, stride=stride)\n",
    "        test_sets = list(imgArs)\n",
    "        predictedLabel = predict(test_sets, labels)\n",
    "        predicted.append(predictedLabel == i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performans: ', 100*predicted.count(True)/len(predicted), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(testData.keys())\n",
    "def predictImg(img, label):\n",
    "    imgArs = prepro1(roundCount=roundCount, img=img, label=classes[label], filterCount=filterCount, filterSize=filterSize, stride=stride)\n",
    "    test_sets = list(imgArs)\n",
    "    predictedLabel = predict(test_sets, labels)\n",
    "    return labels[predictedLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'deer'\n",
    "img = testData[label][0]\n",
    "p = predictImg(img, label)\n",
    "print(p)\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
